{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbRzKerFseXefNts5vydL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kattens/ABUS/blob/main/Junk_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install PubChemPy"
      ],
      "metadata": {
        "id": "56r0c3d1eg4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import pubchempy as pcp\n",
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "0tYFeKueejEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwHvy8ySeavO"
      },
      "outputs": [],
      "source": [
        "#THE PRACTICE CODE FOR SEEING IF THE REQUEST RETURNS THE PAGE WE WANT!\n",
        "'''\n",
        "import requests\n",
        "import webbrowser\n",
        "from IPython.display import IFrame\n",
        "\n",
        "def fetch_bioassay_results(cid):\n",
        "    query = f'https://pubchem.ncbi.nlm.nih.gov/compound/{cid}#section=BioAssay-Results&fullscreen=true'\n",
        "\n",
        "    try:\n",
        "        # Try opening in a new tab (might not work in all environments)\n",
        "        webbrowser.open_new_tab(query)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening in new tab: {e}\")\n",
        "        # Fallback: Open in default browser (new window or tab)\n",
        "        webbrowser.open(query)\n",
        "\n",
        "    # Embed the webpage in the notebook using IFrame\n",
        "    display(IFrame(query, width=800, height=600))\n",
        "\n",
        "    # Make the request with 'requests' (optional)\n",
        "    response = requests.get(query)\n",
        "    if response.status_code == 200:\n",
        "        print(f\"Successfully accessed the website for CID: {cid}\")\n",
        "    else:\n",
        "        print(f\"Failed to access the website for CID: {cid}, Status code: {response.status_code}\")\n",
        "\n",
        "# Example usage\n",
        "fetch_bioassay_results(5330175)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#code for using the PUG API in pubchem:\n",
        "\n",
        "'''\n",
        "import requests\n",
        "\n",
        "def fetch_and_download_csv(cid):\n",
        "    # Update the CSV URL you identified\n",
        "    csv_url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/bioassay/csv\"\n",
        "\n",
        "    # Fetch the CSV file\n",
        "    try:\n",
        "        response = requests.get(csv_url)\n",
        "        if response.status_code == 200:\n",
        "            # Save the CSV file locally\n",
        "            file_name = f\"bioassay_results_{cid}.csv\"\n",
        "            with open(file_name, \"wb\") as file:\n",
        "                file.write(response.content)\n",
        "            print(f\"CSV file downloaded successfully as {file_name}\")\n",
        "        else:\n",
        "            print(f\"Failed to fetch the CSV file. Status code: {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "fetch_and_download_csv(5330175)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "ZpDI53FRgqBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#give example from the bioessay_dict with the first entry\n",
        "#order -> view object -> list of tuples -> every tuple is (str, list of str)\n",
        "tuple_61 = list(bioessay_dict.items())[61]\n",
        "print(tuple_61[0])\n",
        "print(tuple_61[1])\n",
        "#check how many elements are there in the value which is a list\n",
        "print(len(list(bioessay_dict.values())[61]))\n",
        "#also drop the values that are similar only keep the unique ones in the list\n",
        "print(len(set(list(bioessay_dict.values())[61])))\n",
        "print(list(set(list(bioessay_dict.values())[61])))"
      ],
      "metadata": {
        "id": "zUJIeUTSeRXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#When you iterate over a dictionary directly (e.g., for key in bioessay_dict), Python defaults to iterating over the dictionary's keys.\n",
        "#The __iter__ method of a dictionary returns an iterator over the keys. (built in defualt)\n",
        "\n",
        "# Create a new dictionary with updated keys\n",
        "updated_bioessay_dict = {}\n",
        "for key in bioessay_dict:\n",
        "    new_key = key.replace('.csv', '')  # Remove .csv from the key\n",
        "    updated_bioessay_dict[new_key] = bioessay_dict[key]  # Assign the value to the new key\n",
        "\n",
        "# Replace the old dictionary with the updated one\n",
        "bioessay_dict = updated_bioessay_dict\n",
        "\n",
        "print(bioessay_dict.keys())"
      ],
      "metadata": {
        "id": "1dcS9aTVguIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Our Goal**\n",
        "\n",
        "Now we want a dataset structure that:\n",
        "\n",
        "    Stores this triplet clearly\n",
        "\n",
        "    Allows you to:\n",
        "\n",
        "        Run sequence alignments between target and malaria proteins\n",
        "\n",
        "        Analyze which drugs may bind to malaria proteins\n",
        "\n",
        "        Potentially train or evaluate a model later\n",
        "\n",
        "‚úÖ Recommended Dataset Format (JSONL or DataFrame)\n",
        "\n",
        "üß¨ Each row represents a single target‚Äìmalaria protein match\n",
        "\n",
        "{\n",
        "  \"pubchem_id\": \"4735\",\n",
        "  \"target_chain_id\": \"1RKW_A\",\n",
        "  \"target_sequence\": \"MVLSPADKTN...\",\n",
        "  \"malaria_match_id\": \"3D7A_A\",\n",
        "  \"malaria_sequence\": \"MVLSPADKTV...\",\n",
        "  \"percent_identity\": 85.2,\n",
        "  \"alignment_length\": 120,\n",
        "  \"evalue\": 1e-50,\n",
        "  \"bitscore\": 240.0\n",
        "}"
      ],
      "metadata": {
        "id": "QovVtKVDM0Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the Ultimate Dataset:\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "json_path = '/content/drive/MyDrive/Drug Repurposing Project/PubChem_PDB_Results'\n",
        "#Make the main dataset\n",
        "columns = ['pubchem_id', 'target_chain_id', 'target_sequence', 'malaria_match_id', 'malaria_sequence', 'percent_identity', 'alignment_length', 'evalue', 'bitscore']\n",
        "df = pd.DataFrame(columns=columns)"
      ],
      "metadata": {
        "id": "lwa_l-pmMvD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ What it does:\n",
        "\n",
        "    Each folder = a PubChem ID\n",
        "\n",
        "    Each file = a target name (e.g., a protein chain)\n",
        "\n",
        "    Each file contains a list of BLAST hit dictionaries\n",
        "\n",
        "    You want one row per hit, with all relevant info"
      ],
      "metadata": {
        "id": "X06HCmL1NADr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traverse each PubChem ID folder\n",
        "for pubchem_id in os.listdir(json_path):\n",
        "    folder_path = os.path.join(json_path, pubchem_id)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        if not file.endswith('.json'):\n",
        "            continue\n",
        "        target_chain_id = file.replace('.json', '')\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {file_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Skip if message says \"No result found.\"\n",
        "        if isinstance(data, list) and len(data) > 0 and \"message\" in data[0]:\n",
        "            if data[0][\"message\"] == \"No result found.\":\n",
        "                continue\n",
        "\n",
        "        for hit in data:\n",
        "            row = {\n",
        "                'pubchem_id': pubchem_id,\n",
        "                'target_chain_id': target_chain_id,\n",
        "                'malaria_match_id': hit.get(\"subject_id\"),\n",
        "                'percent_identity': hit.get(\"percent_identity\"),\n",
        "                'alignment_length': hit.get(\"alignment_length\"),\n",
        "                'evalue': hit.get(\"evalue\"),\n",
        "                'bitscore': hit.get(\"bitscore\")\n",
        "            }\n",
        "            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "# Preview or save\n",
        "print(df.head())\n",
        "# df.to_csv(\"malaria_alignment_dataset.csv\", index=False)\n",
        "df.to_csv(\"final_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "0_3B8ITJNAsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß¨ Core Goal of the Pipeline\n",
        "\n",
        "The pipeline aims to identify potential repurposing opportunities for existing drugs by leveraging known drug-target interactions and structural homology with malaria proteins. Specifically:\n",
        "\n",
        "  - For each drug in the dataset:\n",
        "  - Retrieve the known protein targets (human or other) that the drug interacts with.\n",
        "\n",
        "  - For each target:\n",
        "\n",
        "      - Download the corresponding PDB structure.\n",
        "\n",
        "      - Extract and isolate individual protein chains.\n",
        "\n",
        "   - For each chain:\n",
        "   - Perform BLASTp search against the PDB database restricted to Plasmodium falciparum (taxID: 5833) to identify structurally similar malaria proteins.\n",
        "\n",
        "   - For each matched malaria protein:\n",
        "\n",
        "      - If a PDB structure is available, download it.\n",
        "\n",
        "      - If only a UniProt ID exists, retrieve the AlphaFold predicted structure.\n",
        "\n",
        "Final Objective:\n",
        "  - Compare the known drug-target interaction site with the structurally similar malaria protein site.\n",
        "  - If significant structural similarity is observed, infer that the drug may also bind to the malaria protein at the same or similar site ‚Üí suggesting a potential for drug repurposing.\n",
        "\n",
        "Summary:\n",
        "\n",
        "Drug ‚Üí Known Target ‚Üí Structure ‚Üí Similar Malaria Protein ‚Üí Binding Prediction"
      ],
      "metadata": {
        "id": "cPcrttJeNWNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Configuration and Paths ---\n",
        "\n",
        "#have the paths set, if not existing, make them\n",
        "BASE_PATH = '/content/drive/MyDrive/Drug Repurposing Project/Interactions_Results'\n",
        "SAVE_PATH = '/content/drive/MyDrive/Drug Repurposing Project/PubChem_PDB_Results'\n",
        "PDB_SAVE_PATH = os.path.join(SAVE_PATH, \"pdb_matches\")\n",
        "\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "os.makedirs(PDB_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# We are combining all interaction and pathway files along with PubChem IDs and other relevant information, we will also focus on using the target PDB ID for further processing.\n",
        "Interaction_folder_path = BASE_PATH\n",
        "\n",
        "# üîÑ Combine all CSV files into one DataFrame\n",
        "combined_df = pd.DataFrame()\n",
        "\n",
        "for filename in os.listdir(Interaction_folder_path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        file_path = os.path.join(Interaction_folder_path, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "        df['source_file'] = filename  # Optional: keep track of original source\n",
        "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "# ‚ûï Add pubchem_id by removing '.csv' and converting to integer\n",
        "combined_df['pubchem_id'] = combined_df['source_file'].str.replace('.csv', '', regex=False).astype(int)\n",
        "\n",
        "# üíæ Save the combined DataFrame to a new CSV\n",
        "output_path = os.path.join(Interaction_folder_path, '/content/drive/MyDrive/Drug Repurposing Project/Combined_Interaction_PDB_Targets.csv')\n",
        "combined_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Combined CSV saved to: {output_path}\")\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Drug Repurposing Project/Combined_Interaction_PDB_Targets.csv')\n",
        "df.columns"
      ],
      "metadata": {
        "id": "3Q-yXOv6NE9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß¨ Key Column Descriptions ‚Äì `combined_targets.csv`\n",
        "\n",
        "| Column Name     | Description                                                                 |\n",
        "|------------------|-----------------------------------------------------------------------------|\n",
        "| `pdbid`          | PDB ID of the protein-ligand structure (e.g., `4I24`)                       |\n",
        "| `title`          | Title/description of the structure (often includes protein and ligand info)|\n",
        "| `expmethod`      | Method used to determine the structure (e.g., X-RAY DIFFRACTION)            |\n",
        "| `resolution`     | Resolution of the structure in √Öngstr√∂ms; lower values = better quality     |\n",
        "| `lignme`         | Ligand(s) present in the structure (e.g., `CLQ` = chloroquine)              |\n",
        "| `cids`           | PubChem Compound IDs (CIDs) for ligands in the structure                    |\n",
        "| `protacxns`      | UniProt accession ID(s) or protein IDs involved in the interaction          |\n",
        "| `geneids`        | NCBI Gene IDs corresponding to the proteins                                 |\n",
        "| `pmid`           | PubMed ID of the publication describing the structure                       |\n",
        "| `dois`           | DOI (Digital Object Identifier) for the structure's publication             |\n",
        "| `pmcids`         | PubMed Central ID, if available                                              |\n",
        "| `pclids`         | PubChem Literature IDs                                                       |\n",
        "| `citations`      | Full text reference or author list                                          |\n",
        "| `source_file`    | Name of the original CSV file (e.g., `444810.csv`) that this row came from  |\n",
        "\n",
        "\n",
        "# ‚úÖ Step 1: Download PDB Structures of Drug Targets\n",
        "\n",
        "We have a list of drugs (PubChem CIDs) and their known protein targets.\n",
        "\n",
        "Goal:\n",
        "Find the 3D structure (PDB file) of each protein target (the human protein that interacts with the drug).\n",
        "\n",
        "How:\n",
        "For each PubChem CID + Target:\n",
        "\n",
        "    Search RCSB Protein Data Bank to see if there‚Äôs a known structure.\n",
        "\n",
        "    If found, download the .pdb or .cif file and save it.\n",
        "\n",
        "This gives you the structures of the human proteins that the drugs are known to interact with."
      ],
      "metadata": {
        "id": "j0nUOLp8NfGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is just a simple query to get the pubchem_id and pdb_id as one query\n",
        "def pdb_query(pubchem_id, pdb_id):\n",
        "    return {\n",
        "        \"query\": {\n",
        "            \"type\": \"group\",\n",
        "            \"logical_operator\": \"and\",\n",
        "            \"nodes\": [\n",
        "                {\n",
        "                    \"type\": \"group\",\n",
        "                    \"logical_operator\": \"and\",\n",
        "                    \"nodes\": [\n",
        "                        {\n",
        "                            \"type\": \"terminal\",\n",
        "                            \"service\": \"text_chem\",\n",
        "                            \"parameters\": {\n",
        "                                \"attribute\": \"rcsb_chem_comp_related.resource_accession_code\",\n",
        "                                \"operator\": \"exact_match\",\n",
        "                                \"negation\": False,\n",
        "                                \"value\": pubchem_id  # string, not list\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"terminal\",\n",
        "                            \"service\": \"text_chem\",\n",
        "                            \"parameters\": {\n",
        "                                \"attribute\": \"rcsb_chem_comp_related.resource_name\",\n",
        "                                \"operator\": \"exact_match\",\n",
        "                                \"value\": \"PubChem\",\n",
        "                                \"negation\": False\n",
        "                            }\n",
        "                        }\n",
        "                    ],\n",
        "                    \"label\": \"nested-attribute\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"terminal\",\n",
        "                    \"service\": \"full_text\",\n",
        "                    \"parameters\": {\n",
        "                        \"value\": pdb_id  # string, not list\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        \"return_type\": \"entry\",\n",
        "        \"request_options\": {\n",
        "            \"paginate\": {\n",
        "                \"start\": 0,\n",
        "                \"rows\": 25\n",
        "            },\n",
        "            \"results_content_type\": [\n",
        "                \"experimental\"\n",
        "            ],\n",
        "            \"sort\": [\n",
        "                {\n",
        "                    \"sort_by\": \"score\",\n",
        "                    \"direction\": \"desc\"\n",
        "                }\n",
        "            ],\n",
        "            \"scoring_strategy\": \"combined\"\n",
        "        }\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "YcNsBYWeNj_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pdb(query, file_dir):\n",
        "    # Step 1: Send query to RCSB -> this work the same as the regex url address modified by previous code\n",
        "    url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    response = requests.post(url, headers=headers, data=json.dumps(query))\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Query failed: {response.status_code}\")\n",
        "        print(response.text)\n",
        "        return\n",
        "\n",
        "    # Step 2: Extract PDB IDs\n",
        "    result = response.json()\n",
        "    pdb_ids = [entry[\"identifier\"] for entry in result.get(\"result_set\", [])]\n",
        "    if not pdb_ids:\n",
        "        print(\"No PDB entries found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found PDB IDs: {pdb_ids}\")\n",
        "\n",
        "    # Step 3: Download PDB files\n",
        "    os.makedirs(file_dir, exist_ok=True)\n",
        "    for pdb_id in pdb_ids:\n",
        "        pdb_url = f\"https://files.rcsb.org/download/{pdb_id}.pdb\"\n",
        "        pdb_response = requests.get(pdb_url)\n",
        "        if pdb_response.status_code == 200:\n",
        "            with open(os.path.join(file_dir, f\"{pdb_id}.pdb\"), \"w\") as f:\n",
        "                f.write(pdb_response.text)\n",
        "            print(f\"Downloaded: {pdb_id}\")\n",
        "        else:\n",
        "            print(f\"Failed to download: {pdb_id}\")\n",
        "\n",
        "\n",
        "#mechanism to download the pdb file and save them in a folder named after the pubchem id  in our target folder\n",
        "#target folder -> make folders with pubchem id -> save each related pdb in it\n",
        "for index, row in df.iterrows():\n",
        "    pubchem_id = row['pubchem_id']\n",
        "    pdb_id = row['pdbid']\n",
        "    query = pdb_query(str(pubchem_id), pdb_id)\n",
        "    download_pdb(query,f'/content/drive/MyDrive/Drug Repurposing Project/PubChem_PDB_Results/{pubchem_id}')\n",
        "    print(f\"Processed PubChem ID: {pubchem_id}\")"
      ],
      "metadata": {
        "id": "leWMCdjdNnX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 2: BLAST Against Malaria Proteins\n",
        "\n",
        "Now you have the sequences of drug target proteins.\n",
        "\n",
        "Goal:\n",
        "Find if these human targets are similar to any malaria proteins (Taxonomy ID 5833).\n",
        "\n",
        "How:\n",
        "You run BLASTp (protein-protein alignment):\n",
        "\n",
        "    For each chain FASTA sequence\n",
        "\n",
        "    Against a filtered BLAST database of only malaria proteins\n",
        "\n",
        "    Save the results (scores, % identity, alignment, PDB ID of malaria proteins)\n",
        "\n",
        "If you find similar malaria proteins ‚Üí there‚Äôs a chance the drug may bind to them.\n",
        "\n",
        "#üéØ Why Chain Separation is Necessary\n",
        "\n",
        "A PDB file may contain:\n",
        "\n",
        "    One protein chain ‚Üí or\n",
        "\n",
        "    Multiple chains (complexes, homo-oligomers, hetero-oligomers)\n",
        "\n",
        "When you want to find if a specific part (a chain) of a known target protein is similar to any malaria protein, you don‚Äôt want to: ‚ùå BLAST the entire PDB complex\n",
        "‚úÖ You want to BLAST each chain separately\n",
        "\n",
        "Reason:\n",
        "Each chain may correspond to:\n",
        "\n",
        "    A different protein\n",
        "\n",
        "    A functional domain\n",
        "\n",
        "    A protein from another species (in complexes)\n",
        "\n",
        "If you BLAST the whole thing ‚Üí you get garbage results.\n",
        "If you BLAST each chain ‚Üí you will correctly detect homologs in malaria proteins (taxonomy 5833).\n",
        "\n",
        "\n",
        "#üéØ What BLAST Can Return\n",
        "\n",
        "When you run BLASTp against PDB or a filtered NCBI database with taxID = 5833, each result hit will contain:\n",
        "\n",
        "    Subject sequence ID (sseqid) ‚Üí This is usually the PDB ID + Chain or a UniProt ID\n",
        "\n",
        "    Alignment score, E-value, percent identity ‚Üí Already useful\n",
        "\n",
        "    Sometimes, the definition line of the matched sequence ‚Üí Contains the actual protein name\n",
        "\n",
        "You can customize the output format to include:\n",
        "\n",
        "‚úÖ sseqid ‚Üí PDB ID or UniProt ID\n",
        "\n",
        "‚úÖ stitle ‚Üí Full title of matched protein\n",
        "\n",
        "‚úÖ taxid ‚Üí Organism tax ID\n",
        "\n",
        "‚úÖ slen ‚Üí Length of matched sequence\n",
        "\n",
        "‚úÖ evalue, pident, bitscore ‚Üí Scores\n",
        "\n",
        "What we want:\n",
        "\n",
        "Matched PDB/UniProt ID\n",
        "\n",
        "Protein name\n",
        "\n",
        "Any metadata\n"
      ],
      "metadata": {
        "id": "s9KuTkS0NrdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_protein_chains(pdb_file_path):\n",
        "    \"\"\"\n",
        "    Extracts protein chain sequences from a PDB file and saves them as FASTA files.\n",
        "\n",
        "    Args:\n",
        "        pdb_file_path (str): Path to the PDB file.\n",
        "\n",
        "    Returns:\n",
        "        list: List of generated FASTA file paths.\n",
        "    \"\"\"\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure(\"structure\", pdb_file_path)\n",
        "    ppb = PPBuilder()\n",
        "    chain_fastas = []\n",
        "\n",
        "    pdb_path = Path(pdb_file_path)\n",
        "    output_dir = pdb_path.parent\n",
        "    pdb_name = pdb_path.stem\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            peptides = ppb.build_peptides(chain)\n",
        "            if peptides:\n",
        "                sequence = ''.join(str(peptide.get_sequence()) for peptide in peptides)\n",
        "                if sequence:\n",
        "                    chain_id = chain.id\n",
        "                    fasta_path = output_dir / f\"{pdb_name}_{chain_id}.fasta\"\n",
        "                    with open(fasta_path, \"w\") as f:\n",
        "                        f.write(f\">{pdb_name}_{chain_id}\\n{sequence}\\n\")\n",
        "                    chain_fastas.append(str(fasta_path))\n",
        "    return chain_fastas\n",
        "\n",
        "folders_path = '/content/drive/MyDrive/Drug Repurposing Project/PubChem_PDB_Results'\n",
        "\n",
        "# Iterate through each folder in folders_path\n",
        "for folder_name in os.listdir(folders_path):\n",
        "    folder_path = os.path.join(folders_path, folder_name)\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Iterate through each file in the folder\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            if file_name.endswith('.pdb'):\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                extract_protein_chains(file_path)\n",
        "                print(f\"Processed {file_name} in {folder_name}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PzHjOzwiNtkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Do the blast search with each .fasta file sequence and toxonomy = 5833**\n",
        "\n",
        "‚úÖ Step 3: BLAST Against Malaria Proteins\n",
        "\n",
        "Now you have the sequences of drug target proteins.\n",
        "\n",
        "Goal:\n",
        "Find if these human targets are similar to any malaria proteins (Taxonomy ID 5833).\n",
        "\n",
        "How:\n",
        "You run BLASTp (protein-protein alignment):\n",
        "\n",
        "    For each chain FASTA sequence\n",
        "\n",
        "    Against a filtered BLAST database of only malaria proteins\n",
        "\n",
        "    Save the results (scores, % identity, alignment, PDB ID of malaria proteins)\n",
        "\n",
        "If you find similar malaria proteins ‚Üí there‚Äôs a chance the drug may bind to them.\n",
        "‚úÖ Step 4: Save Top 3 Matches\n",
        "\n",
        "From the BLAST output, for each target chain:\n",
        "\n",
        "    Pick the top 3 similar malaria proteins\n",
        "\n",
        "    Save their details (ID, score, identity, etc.) in a JSON file\n",
        "\n",
        "    If no hit found, mark as \"NAN\""
      ],
      "metadata": {
        "id": "WMS1793ONzLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def blast_sequence(fasta_file, tax_id=\"5833\"):\n",
        "\n",
        "    \"\"\"Extract sequence from FASTA and perform remote BLAST.\"\"\"\n",
        "    with open(fasta_file, 'r') as f:\n",
        "        sequence = ''.join([line.strip() for line in f if not line.startswith(\">\")])\n",
        "\n",
        "    print(f\"[INFO] Running BLAST for: {fasta_file}\")\n",
        "\n",
        "    output_json = os.path.splitext(fasta_file)[0] + \".json\"\n",
        "\n",
        "\n",
        "    \"\"\" Run the BlastP on the information above from the .fasta files which is the sequence for each chain\"\"\"\n",
        "    try:\n",
        "        result_handle = NCBIWWW.qblast(\n",
        "            program=\"blastp\",\n",
        "            database=\"pdb\",\n",
        "            sequence=sequence,\n",
        "            entrez_query=f\"txid{tax_id}[ORGN]\",\n",
        "            hitlist_size=3\n",
        "        )\n",
        "\n",
        "        blast_record = NCBIXML.read(result_handle)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        if not blast_record.alignments:\n",
        "            print(\"[INFO] No result found.\")\n",
        "            results.append({\"message\": \"No result found.\"})\n",
        "        else:\n",
        "            print(f\"[‚úì] BLAST Results for {fasta_file}:\")\n",
        "            for alignment in blast_record.alignments:\n",
        "                hsp = alignment.hsps[0]  # Take the best HSP\n",
        "                result = {\n",
        "                    \"subject_id\": alignment.accession,\n",
        "                    \"title\": alignment.title,\n",
        "                    \"percent_identity\": hsp.identities / hsp.align_length * 100,\n",
        "                    \"alignment_length\": hsp.align_length,\n",
        "                    \"evalue\": hsp.expect,\n",
        "                    \"bitscore\": hsp.score\n",
        "                }\n",
        "                results.append(result)\n",
        "                print(f\"  ‚Üí Subject ID: {result['subject_id']}\")\n",
        "                print(f\"     Title    : {result['title']}\")\n",
        "                print(f\"     Identity : {hsp.identities}/{hsp.align_length}\")\n",
        "                print(f\"     E-value  : {hsp.expect}\")\n",
        "                print(f\"     Score    : {hsp.score}\\n\")\n",
        "\n",
        "\n",
        "        \"\"\" Save results to JSON -> whatever happens we will save a json file for each of the .fasta files whether we have results or no results \"\"\"\n",
        "        with open(output_json, \"w\") as f:\n",
        "            json.dump(results, f, indent=4)\n",
        "        print(f\"[‚úì] Results saved to: {output_json}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Error during BLAST: {e}\")\n",
        "        with open(output_json, \"w\") as f:\n",
        "            json.dump({\"error\": str(e)}, f, indent=4)\n",
        "        print(f\"[!] Error info saved to: {output_json}\")"
      ],
      "metadata": {
        "id": "JHO-7JadNzyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Usage\"\"\"\n",
        "\n",
        "parent_folder = '/content/drive/MyDrive/Drug Repurposing Project/PubChem_PDB_Results'\n",
        "\n",
        "for folder in os.listdir(parent_folder):  # Loop over folders\n",
        "    folder_path = os.path.join(parent_folder, folder)\n",
        "\n",
        "    if os.path.isdir(folder_path):  # Make sure it's a folder\n",
        "        for file in os.listdir(folder_path):  # Loop over files inside the folder\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "\n",
        "            if file.endswith('.fasta'):  # Only FASTA files\n",
        "                blast_sequence(file_path)\n"
      ],
      "metadata": {
        "id": "OqZb-3rmN1c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Step 5: Download Matched Malaria Protein Structures\n",
        "\n",
        "For each of the top malaria proteins found in Step 4:\n",
        "\n",
        "    If they have a PDB structure ‚Üí Download it.\n",
        "\n",
        "    If not ‚Üí Download the AlphaFold predicted structure.\n",
        "\n",
        "Why? You will use this structure later to:\n",
        "\n",
        "    Analyze binding\n",
        "\n",
        "    Run docking\n",
        "\n",
        "    See if the drug can bind to this malaria protein\n",
        "\n",
        "üöÄ Why are we doing this?\n",
        "\n",
        "The whole logic is:\n",
        "\n",
        "    Known drug binds to known human target.\n",
        "\n",
        "    If that target looks like a malaria protein ‚Üí the drug may also bind to the malaria protein.\n",
        "\n",
        "    By checking structural similarity, you reduce the search space of possible binding sites.\n",
        "\n"
      ],
      "metadata": {
        "id": "e9z4vKP5N5o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Sequence Extraction ---\n",
        "\n",
        "# --- 3. BLAST Functions ---\n",
        "def blast_sequence(sequence, tax_id=\"5833\"):\n",
        "    \"\"\"Performs a BLAST search against the PDB database.\"\"\"\n",
        "    result_handle = NCBIWWW.qblast(\n",
        "        program=\"blastp\",\n",
        "        database=\"pdb\",\n",
        "        sequence=sequence,\n",
        "        entrez_query=f\"txid{tax_id}[ORGN]\",\n",
        "        hitlist_size=3\n",
        "    )\n",
        "    return NCBIXML.read(result_handle)\n",
        "\n",
        "def safe_blast_with_timeout(sequence, timeout=600):\n",
        "    \"\"\"Performs BLAST with a timeout to prevent indefinite waiting.\"\"\"\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        future = executor.submit(blast_sequence, sequence)\n",
        "        try:\n",
        "            return future.result(timeout=timeout)\n",
        "        except concurrent.futures.TimeoutError:\n",
        "            print(\"‚è∞ Timeout reached! Skipping this chain.\")\n",
        "            return None\n",
        "\n",
        "# --- 4. UniProt PDB Mapping ---\n",
        "def get_pdb_for_accession(accession):\n",
        "    \"\"\"Retrieves PDB IDs associated with a UniProt accession.\"\"\"\n",
        "    url = f\"https://rest.uniprot.org/uniprotkb/{accession}.json\"\n",
        "    response = requests.get(url)\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        pdbs = []\n",
        "        for xref in data.get(\"uniProtKBCrossReferences\", []):\n",
        "            if xref[\"database\"] == \"PDB\":\n",
        "                pdbs.append(xref[\"id\"])\n",
        "        return pdbs\n",
        "    return []\n",
        "\n",
        "# --- 5. PDB and AlphaFold Download ---\n",
        "def download_file(url, dest_path, description):\n",
        "    \"\"\"Downloads a file from a URL.\"\"\"\n",
        "    if os.path.exists(dest_path):\n",
        "        print(f\"üì¶ Skipping already downloaded {description}\")\n",
        "        return dest_path\n",
        "    r = requests.get(url)\n",
        "    if r.ok:\n",
        "        with open(dest_path, 'w') as f:\n",
        "            f.write(r.text)\n",
        "        print(f\"üì• Downloaded {description}\")\n",
        "        return dest_path\n",
        "    print(f\"‚ö†Ô∏è Failed to download {description}\")\n",
        "    return None\n",
        "\n",
        "def download_pdb(pdb_id, dest_folder):\n",
        "    \"\"\"Downloads a PDB file.\"\"\"\n",
        "    dest_path = os.path.join(dest_folder, f\"{pdb_id}.pdb\")\n",
        "    url = f\"https://files.rcsb.org/download/{pdb_id}.pdb\"\n",
        "    return download_file(url, dest_path, f\"PDB {pdb_id}\")\n",
        "\n",
        "def download_alphafold(uniprot_id, dest_folder):\n",
        "    \"\"\"Downloads an AlphaFold model.\"\"\"\n",
        "    file_name = f\"AF-{uniprot_id}.pdb\"\n",
        "    dest_path = os.path.join(dest_folder, file_name)\n",
        "    url = f\"https://alphafold.ebi.ac.uk/files/{file_name}\"\n",
        "    return download_file(url, dest_path, f\"AlphaFold model for {uniprot_id}\")\n",
        "\n",
        "# --- 6. Main Processing Loop ---\n",
        "for folder_name in os.listdir(BASE_PATH):\n",
        "    folder_path = os.path.join(BASE_PATH, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.pdb'):\n",
        "                pdb_file_path = os.path.join(folder_path, file)\n",
        "                pdb_id = file.replace('.pdb', '')\n",
        "                pubchem_id = folder_name\n",
        "\n",
        "                print(f\"\\nüìÑ Processing {pdb_id} from PubChem {pubchem_id}\")\n",
        "                protein_chains = extract_protein_chains(pdb_file_path)\n",
        "\n",
        "                for chain_id, sequence in protein_chains.items():\n",
        "                    json_name = f\"{pubchem_id}_{pdb_id}_{chain_id}.json\"\n",
        "                    json_file_path = os.path.join(SAVE_PATH, json_name)\n",
        "\n",
        "                    if os.path.exists(json_file_path):\n",
        "                        print(f\"‚è≠Ô∏è Skipping chain {chain_id} (already processed)\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"\\nüß¨ Chain {chain_id} | Length: {len(sequence)}\")\n",
        "                    result = safe_blast_with_timeout(sequence)\n",
        "\n",
        "                    if result and result.alignments:\n",
        "                        top_hits = []\n",
        "                        for alignment in result.alignments[:3]:\n",
        "                            hsp = alignment.hsps[0]\n",
        "                            pdb_code, chain_code = None, None\n",
        "                            parts = alignment.hit_id.split('|')\n",
        "                            if alignment.hit_id.startswith('pdb|') and len(parts) >= 3:\n",
        "                                pdb_code, chain_code = parts[1], parts[2]\n",
        "\n",
        "                            hit = {\n",
        "                                \"hit_def\": alignment.hit_def,\n",
        "                                \"e_value\": hsp.expect,\n",
        "                                \"score\": hsp.score,\n",
        "                                \"query\": hsp.query[:60],\n",
        "                                \"subject\": hsp.sbjct[:60],\n",
        "                                \"pdb_code\": pdb_code,\n",
        "                                \"chain\": chain_code\n",
        "                            }\n",
        "\n",
        "                            acc = parts[1] if parts else None\n",
        "                            if acc:\n",
        "                                mapped_pdbs = get_pdb_for_accession(acc)\n",
        "                                hit['mapped_pdbs'] = mapped_pdbs\n",
        "                                for pdb_id_hit in mapped_pdbs:\n",
        "                                    download_pdb(pdb_id_hit, PDB_SAVE_PATH)\n",
        "                                if not mapped_pdbs:\n",
        "                                    download_alphafold(acc, PDB_SAVE_PATH)\n",
        "\n",
        "                            top_hits.append(hit)\n",
        "\n",
        "                        with open(json_file_path, 'w') as f:\n",
        "                            json.dump(top_hits, f, indent=2)\n",
        "                        print(f\"üíæ Saved results to {json_file_path}\")\n",
        "\n",
        "                    else:\n",
        "                        print(f\"‚ùå No valid BLAST result for {pdb_id} Chain {chain_id}\")\n",
        "                        no_hits_file = os.path.join(SAVE_PATH, \"no_pdb_hits.txt\")\n",
        "                        with open(no_hits_file, 'a') as f:\n",
        "                            f.write(f\"{pubchem_id}_{pdb_id}_{chain_id}\\n\")"
      ],
      "metadata": {
        "id": "smTYk56UN7c4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}